{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import shakespeare\n",
    "from nltk.corpus import genesis\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.corpus import brown\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "from sklearn import datasets, svm, tree, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "from nltk.book import *\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.1 Consider the following code, it computes 3 different features. Can you tell what each feature computes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeFeature1(text):\n",
    "    len(text)\n",
    "    sum = 0;\n",
    "    for word in text:\n",
    "        sum+= len(word)\n",
    "    print(sum)\n",
    "    return sum/len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature1: The ratio of the numbers of characters to the numbers of words in the inputted text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRelevantCategories(text, num):\n",
    "    taggedWordList = pos_tag(text)\n",
    "    fd = nltk.FreqDist((t1, t2) for ((w1, t1), (w2, t2)) in nltk.bigrams(taggedWordList))\n",
    "    res = []\n",
    "    for (tag, freq) in fd.most_common(num):\n",
    "        res.append(tag)\n",
    "    return res\n",
    "\n",
    "def computeFeature2(text, cats):\n",
    "    taggedWordList = pos_tag(text)\n",
    "    fd = nltk.FreqDist((t1, t2) for ((w1, t1), (w2, t2)) in nltk.bigrams(taggedWordList))\n",
    "    res = []\n",
    "    for cat in cats:\n",
    "        res.append(fd.freq(cat))\n",
    "    return res\n",
    "\n",
    "# row 6:  res.append(str(tag)) -> res.append(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getRelevantCategories: get num most freqently occuring tag bigrams in the inputted text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature2: The count of each tag bigram(categroy) divided by the total number of inputted tag bigrams(categories), namely the frequency of the each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeFeature3(text):\n",
    "    taggedWordList = pos_tag(text, tagset='universal')\n",
    "    fd_tags = nltk.FreqDist(tag for (word, tag) in taggedWordList)\n",
    "    fd_words = nltk.FreqDist(word for (word, tag) in taggedWordList)\n",
    "    return fd_words.freq(';')/fd_tags.freq('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature3: The frequency of ';' in the most frequent words divided by the frequency of '.' in the most frequent tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388\n",
      "358\n",
      "333\n",
      "424\n",
      "386\n",
      "365\n",
      "397\n",
      "382\n",
      "381\n",
      "355\n",
      "361\n",
      "379\n",
      "354\n",
      "373\n",
      "365\n",
      "365\n",
      "367\n",
      "381\n",
      "342\n",
      "341\n",
      "321\n",
      "362\n",
      "374\n",
      "376\n",
      "382\n",
      "385\n",
      "360\n",
      "370\n",
      "387\n",
      "368\n",
      "369\n",
      "309\n",
      "371\n",
      "381\n",
      "421\n",
      "414\n",
      "407\n",
      "295\n",
      "350\n",
      "438\n",
      "360\n",
      "396\n",
      "399\n",
      "399\n",
      "385\n",
      "363\n",
      "365\n",
      "388\n",
      "420\n",
      "399\n",
      "417\n",
      "375\n",
      "376\n",
      "349\n",
      "392\n",
      "397\n",
      "386\n",
      "377\n",
      "331\n",
      "336\n",
      "388\n",
      "388\n",
      "371\n",
      "348\n",
      "389\n",
      "392\n",
      "399\n",
      "405\n",
      "397\n",
      "411\n",
      "451\n",
      "393\n",
      "363\n",
      "386\n",
      "408\n",
      "422\n",
      "373\n",
      "384\n",
      "406\n",
      "362\n",
      "342\n",
      "372\n",
      "352\n",
      "407\n",
      "372\n",
      "404\n",
      "350\n",
      "395\n",
      "392\n",
      "374\n",
      "394\n",
      "435\n",
      "437\n",
      "361\n",
      "416\n",
      "417\n",
      "417\n",
      "394\n",
      "376\n",
      "444\n",
      "394\n",
      "323\n",
      "356\n",
      "364\n",
      "377\n",
      "320\n",
      "351\n",
      "386\n",
      "380\n",
      "408\n",
      "376\n",
      "395\n",
      "374\n",
      "366\n",
      "380\n",
      "337\n",
      "358\n",
      "351\n",
      "368\n",
      "380\n",
      "395\n",
      "338\n",
      "317\n",
      "355\n",
      "327\n",
      "294\n",
      "407\n",
      "349\n",
      "314\n",
      "359\n",
      "356\n",
      "309\n",
      "324\n",
      "394\n",
      "383\n",
      "386\n",
      "365\n",
      "326\n",
      "379\n",
      "352\n",
      "368\n",
      "334\n",
      "369\n",
      "340\n",
      "394\n",
      "363\n",
      "385\n",
      "377\n",
      "373\n",
      "405\n",
      "382\n",
      "397\n",
      "406\n",
      "439\n",
      "374\n",
      "358\n",
      "320\n",
      "326\n",
      "345\n",
      "340\n",
      "306\n",
      "390\n",
      "376\n",
      "374\n",
      "351\n",
      "369\n",
      "415\n",
      "387\n",
      "382\n",
      "387\n",
      "359\n",
      "385\n",
      "395\n",
      "409\n",
      "384\n",
      "381\n",
      "390\n",
      "405\n",
      "410\n",
      "378\n",
      "412\n",
      "356\n",
      "381\n",
      "380\n",
      "368\n",
      "372\n",
      "411\n",
      "390\n",
      "424\n",
      "450\n",
      "472\n",
      "445\n",
      "361\n",
      "384\n",
      "381\n",
      "339\n",
      "408\n",
      "388\n",
      "422\n",
      "405\n",
      "431\n",
      "410\n",
      "373\n",
      "414\n",
      "441\n",
      "439\n",
      "417\n",
      "401\n",
      "384\n",
      "387\n",
      "399\n",
      "394\n",
      "451\n",
      "397\n",
      "396\n",
      "379\n",
      "443\n",
      "403\n",
      "413\n",
      "363\n",
      "360\n",
      "392\n",
      "379\n",
      "371\n",
      "354\n",
      "397\n",
      "346\n",
      "359\n",
      "376\n",
      "381\n",
      "404\n",
      "377\n",
      "373\n",
      "354\n",
      "380\n",
      "371\n",
      "342\n",
      "376\n",
      "365\n",
      "354\n",
      "384\n",
      "425\n",
      "346\n",
      "372\n",
      "383\n",
      "367\n",
      "378\n",
      "423\n",
      "376\n",
      "361\n",
      "375\n",
      "398\n",
      "390\n",
      "378\n",
      "368\n",
      "378\n",
      "355\n",
      "383\n",
      "383\n",
      "361\n",
      "342\n",
      "350\n",
      "388\n",
      "343\n",
      "380\n",
      "364\n",
      "419\n",
      "393\n",
      "398\n",
      "487\n",
      "418\n",
      "405\n",
      "361\n",
      "419\n",
      "393\n",
      "395\n",
      "378\n",
      "389\n",
      "386\n",
      "394\n",
      "343\n",
      "380\n",
      "373\n",
      "419\n",
      "356\n",
      "392\n",
      "383\n",
      "401\n",
      "374\n",
      "415\n",
      "374\n",
      "384\n",
      "393\n",
      "368\n",
      "378\n",
      "420\n",
      "396\n",
      "360\n",
      "379\n",
      "381\n",
      "366\n",
      "328\n",
      "357\n",
      "351\n",
      "347\n",
      "357\n",
      "337\n",
      "380\n",
      "313\n",
      "355\n",
      "355\n",
      "319\n",
      "323\n",
      "355\n",
      "381\n",
      "330\n",
      "381\n",
      "413\n",
      "387\n",
      "408\n",
      "354\n",
      "383\n",
      "311\n",
      "337\n",
      "376\n",
      "399\n",
      "342\n",
      "382\n",
      "366\n",
      "331\n",
      "327\n",
      "367\n",
      "349\n",
      "335\n",
      "353\n",
      "322\n",
      "388\n",
      "339\n",
      "333\n",
      "274\n",
      "304\n",
      "364\n",
      "359\n",
      "351\n",
      "382\n",
      "379\n",
      "388\n",
      "387\n",
      "372\n",
      "363\n",
      "352\n",
      "333\n",
      "349\n",
      "341\n",
      "378\n",
      "360\n",
      "324\n",
      "352\n",
      "342\n",
      "386\n",
      "315\n",
      "354\n",
      "305\n",
      "331\n",
      "321\n",
      "385\n",
      "347\n",
      "365\n",
      "355\n",
      "388\n",
      "361\n",
      "372\n",
      "339\n",
      "376\n",
      "272\n",
      "278\n",
      "316\n",
      "333\n",
      "303\n",
      "341\n",
      "367\n",
      "343\n",
      "331\n",
      "375\n",
      "335\n",
      "359\n",
      "347\n",
      "340\n",
      "325\n",
      "358\n",
      "321\n",
      "317\n",
      "312\n",
      "356\n",
      "338\n",
      "393\n",
      "360\n",
      "355\n",
      "415\n",
      "303\n",
      "345\n",
      "383\n",
      "412\n",
      "356\n",
      "322\n",
      "322\n",
      "353\n",
      "332\n",
      "325\n",
      "339\n",
      "325\n",
      "339\n",
      "330\n",
      "292\n",
      "328\n",
      "353\n",
      "329\n",
      "381\n",
      "331\n",
      "336\n",
      "312\n",
      "355\n",
      "338\n",
      "344\n",
      "337\n",
      "368\n",
      "363\n",
      "357\n",
      "378\n",
      "368\n",
      "371\n",
      "362\n",
      "371\n",
      "358\n",
      "330\n",
      "383\n",
      "312\n",
      "337\n",
      "325\n",
      "316\n",
      "365\n",
      "369\n",
      "395\n",
      "376\n",
      "383\n",
      "312\n",
      "353\n",
      "350\n",
      "351\n",
      "327\n",
      "300\n",
      "342\n",
      "348\n",
      "309\n",
      "340\n",
      "381\n",
      "391\n",
      "382\n",
      "325\n",
      "366\n",
      "342\n",
      "351\n",
      "331\n",
      "345\n",
      "408\n",
      "352\n",
      "318\n",
      "382\n",
      "347\n",
      "330\n",
      "341\n",
      "335\n",
      "344\n",
      "326\n",
      "416\n",
      "342\n",
      "310\n",
      "353\n",
      "336\n",
      "364\n",
      "383\n",
      "386\n",
      "339\n",
      "377\n",
      "335\n",
      "360\n",
      "366\n",
      "299\n",
      "303\n",
      "304\n",
      "339\n",
      "370\n",
      "378\n",
      "315\n",
      "376\n",
      "345\n",
      "342\n",
      "367\n",
      "390\n",
      "367\n",
      "351\n",
      "316\n",
      "339\n",
      "387\n",
      "358\n",
      "340\n",
      "351\n",
      "333\n",
      "365\n",
      "327\n",
      "363\n",
      "357\n",
      "308\n",
      "365\n",
      "336\n",
      "276\n",
      "361\n",
      "394\n",
      "369\n",
      "365\n",
      "339\n",
      "387\n",
      "320\n",
      "347\n",
      "315\n",
      "338\n",
      "318\n",
      "360\n",
      "327\n",
      "301\n",
      "287\n",
      "330\n",
      "370\n",
      "381\n",
      "344\n",
      "358\n",
      "339\n",
      "331\n",
      "350\n",
      "371\n",
      "336\n",
      "374\n",
      "365\n",
      "341\n",
      "325\n",
      "330\n",
      "337\n",
      "368\n",
      "345\n",
      "321\n",
      "381\n",
      "337\n",
      "343\n",
      "341\n",
      "290\n",
      "371\n",
      "337\n",
      "340\n",
      "348\n",
      "346\n",
      "341\n",
      "370\n",
      "338\n",
      "374\n",
      "373\n",
      "329\n",
      "303\n",
      "304\n",
      "309\n",
      "386\n",
      "422\n",
      "360\n",
      "370\n",
      "347\n",
      "333\n",
      "349\n",
      "361\n",
      "339\n",
      "320\n",
      "361\n",
      "318\n",
      "303\n",
      "346\n",
      "330\n",
      "327\n",
      "358\n",
      "363\n",
      "351\n",
      "347\n",
      "363\n",
      "351\n",
      "330\n",
      "366\n",
      "279\n",
      "360\n",
      "323\n",
      "344\n",
      "343\n",
      "378\n",
      "358\n",
      "            GOLD  FEATURE1  FEATURE2_0  FEATURE2_1  FEATURE2_2  FEATURE2_3  \\\n",
      "290     melville      3.74    0.020202    0.030303    0.010101    0.040404   \n",
      "291     melville      3.84    0.050505    0.050505    0.010101    0.060606   \n",
      "292     melville      3.93    0.020202    0.020202    0.020202    0.070707   \n",
      "293     melville      3.68    0.050505    0.040404    0.010101    0.040404   \n",
      "294     melville      3.78    0.070707    0.040404    0.040404    0.010101   \n",
      "295     melville      4.20    0.050505    0.020202    0.030303    0.030303   \n",
      "296     melville      3.96    0.010101    0.030303    0.000000    0.000000   \n",
      "297     melville      3.60    0.050505    0.030303    0.030303    0.020202   \n",
      "298     melville      3.79    0.020202    0.030303    0.010101    0.010101   \n",
      "299     melville      3.81    0.030303    0.040404    0.040404    0.050505   \n",
      "300  shakespeare      3.66    0.010101    0.020202    0.000000    0.000000   \n",
      "301  shakespeare      3.28    0.010101    0.000000    0.000000    0.010101   \n",
      "302  shakespeare      3.57    0.010101    0.010101    0.030303    0.030303   \n",
      "303  shakespeare      3.51    0.000000    0.030303    0.030303    0.010101   \n",
      "304  shakespeare      3.47    0.000000    0.030303    0.020202    0.010101   \n",
      "305  shakespeare      3.57    0.020202    0.010101    0.030303    0.020202   \n",
      "306  shakespeare      3.37    0.010101    0.050505    0.030303    0.040404   \n",
      "307  shakespeare      3.80    0.020202    0.020202    0.030303    0.050505   \n",
      "308  shakespeare      3.13    0.040404    0.030303    0.020202    0.000000   \n",
      "309  shakespeare      3.55    0.020202    0.040404    0.030303    0.010101   \n",
      "\n",
      "     FEATURE2_4  FEATURE3  \n",
      "290    0.020202  0.083333  \n",
      "291    0.020202  0.166667  \n",
      "292    0.020202  0.250000  \n",
      "293    0.060606  0.133333  \n",
      "294    0.010101  0.428571  \n",
      "295    0.020202  0.000000  \n",
      "296    0.000000  0.285714  \n",
      "297    0.010101  0.125000  \n",
      "298    0.010101  0.071429  \n",
      "299    0.030303  0.000000  \n",
      "300    0.020202  0.000000  \n",
      "301    0.000000  0.000000  \n",
      "302    0.030303  0.000000  \n",
      "303    0.040404  0.000000  \n",
      "304    0.020202  0.055556  \n",
      "305    0.010101  0.047619  \n",
      "306    0.030303  0.000000  \n",
      "307    0.020202  0.000000  \n",
      "308    0.010101  0.000000  \n",
      "309    0.010101  0.000000  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    melville       0.84      0.87      0.86        62\n",
      " shakespeare       0.86      0.83      0.84        58\n",
      "\n",
      "    accuracy                           0.85       120\n",
      "   macro avg       0.85      0.85      0.85       120\n",
      "weighted avg       0.85      0.85      0.85       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "num = 300\n",
    "numTokens = 100\n",
    "numCategoriesToConsider = 5\n",
    "\n",
    "# Gold: 300 melville rows + 300 shakespeare rows\n",
    "df['GOLD'] = [\"melville\" for i in range(0,num)]+[\"shakespeare\" for i in range(0,num)]\n",
    "\n",
    "# Add in Feature1\n",
    "df['FEATURE1'] = [computeFeature1(gutenberg.words('melville-moby_dick.txt')[i*numTokens:(i+1)*numTokens]) for i in range(0,num)]+[computeFeature1(gutenberg.words('shakespeare-hamlet.txt')[i*numTokens:(i+1)*numTokens]) for i in range(0,num)]\n",
    "\n",
    "# Add in Feature2\n",
    "allTexts = gutenberg.words('melville-moby_dick.txt')[:num*numTokens]+gutenberg.words('shakespeare-hamlet.txt')[num*numTokens]\n",
    "tags = getRelevantCategories(allTexts, numCategoriesToConsider)\n",
    "for f in range(0,numCategoriesToConsider):\n",
    "    df['FEATURE2_'+str(f)] = [computeFeature2(gutenberg.words('melville-moby_dick.txt')[i*numTokens:(i+1)*numTokens], tags)[f] for i in range(0,num)]+[computeFeature2(gutenberg.words('shakespeare-hamlet.txt')[i*numTokens:(i+1)*numTokens], tags)[f] for i in range(0,num)]\n",
    "\n",
    "# Add in Feature3\n",
    "df['FEATURE3'] = [computeFeature3(gutenberg.words('melville-moby_dick.txt')[i*numTokens:(i+1)*numTokens]) for i in range(0,num)]+[computeFeature3(gutenberg.words('shakespeare-hamlet.txt')[i*numTokens:(i+1)*numTokens]) for i in range(0,num)]\n",
    "\n",
    "# We can inspect what the features look like\n",
    "print(df[290:310])\n",
    "\n",
    "\n",
    "# Now we train a classifier similar to what we did for Named Entity classifcation\n",
    "x = df.iloc[:, 1:len(df.columns)]\n",
    "y = df.iloc[:, [0]]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "c_tree = DecisionTreeClassifier(max_depth=4)\n",
    "c_tree.fit(x_train, y_train)\n",
    "\n",
    "# ... and evaluate it\n",
    "predicted = list(c_tree.predict(x_test))\n",
    "gold = list(y_test.loc[:, \"GOLD\"])\n",
    "print(classification_report(gold,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you extend the classifier with new features. Implement a method computeFeature4 that also takes a list of words as input and returns the average sentence length in tokens as features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeFeature4(text):\n",
    "    text_1= ' '.join(text)\n",
    "    sents = sent_tokenize(text_1)\n",
    "    count = 0\n",
    "\n",
    "    for sent in sents:\n",
    "        sent1 = word_tokenize(sent)\n",
    "        count += len(sent1)\n",
    "    return count/len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in Feature4\n",
    "df['SENTENCELENGTH'] = [computeFeature4(gutenberg.words('melville-moby_dick.txt')[i*numTokens:(i+1)*numTokens]) for i in range(0,num)]+[computeFeature4(gutenberg.words('shakespeare-hamlet.txt')[i*numTokens:(i+1)*numTokens]) for i in range(0,num)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMostFrequentPreps(text, num):\n",
    "    taggedWordList = pos_tag(text, tagset='universal')\n",
    "    fd = nltk.FreqDist(w for (w, t) in taggedWordList if t == 'ADP')\n",
    "    preps = []\n",
    "    for (prep, freq) in fd.most_common(num):\n",
    "        preps.append(prep)\n",
    "    return preps\n",
    "\n",
    "def computeFeature5(text, cats):\n",
    "    taggedWordList = pos_tag(text, tagset='universal')\n",
    "    fd = nltk.FreqDist(w for (w, t) in taggedWordList)\n",
    "    res = []\n",
    "    for cat in cats:\n",
    "        res.append(fd.freq(cat))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['of', 'in', 'that', 'with', 'as']\n"
     ]
    }
   ],
   "source": [
    "#  Add in Feature5\n",
    "tags = getMostFrequentPreps(allTexts, 5)\n",
    "print(tags)\n",
    "for f in range(0,5):\n",
    "    df['PREP_'+str(f)] = [computeFeature5(gutenberg.words('melville-moby_dick.txt')[i*numTokens:(i+1)*numTokens], tags)[f] for i in range(0,num)]+[computeFeature5(gutenberg.words('shakespeare-hamlet.txt')[i*numTokens:(i+1)*numTokens], tags)[f] for i in range(0,num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stops = stopwords.words('english')\n",
    "\n",
    "def getMostFrequentContentWords(text, num):\n",
    "    ConWords = []\n",
    "    fd = nltk.FreqDist(w for w in text if (w.lower() not in stops) and (w.isalpha()))\n",
    "    for (Cword, freq) in fd.most_common(num):\n",
    "        ConWords.append(Cword)\n",
    "    return ConWords\n",
    "\n",
    "def computeFeature6(text, cats):\n",
    "    fd = nltk.FreqDist(w for w in text)\n",
    "    res = []\n",
    "    for cat in cats:\n",
    "        res.append(fd.freq(cat))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'like', 'upon', 'sea', 'whale']\n"
     ]
    }
   ],
   "source": [
    "# Add in Feature6\n",
    "tags = getMostFrequentContentWords(allTexts, 5)\n",
    "print(tags)\n",
    "for f in range(0,5):\n",
    "    df['FUNCTIONWORD_'+str(f)] = [computeFeature6(gutenberg.words('melville-moby_dick.txt')[i*numTokens:(i+1)*numTokens], tags)[f] for i in range(0,num)]+[computeFeature6(gutenberg.words('shakespeare-hamlet.txt')[i*numTokens:(i+1)*numTokens], tags)[f] for i in range(0,num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            GOLD  FEATURE1  FEATURE2_0  FEATURE2_1  FEATURE2_2  FEATURE2_3  \\\n",
      "290     melville      3.74    0.020202    0.030303    0.010101    0.040404   \n",
      "291     melville      3.84    0.050505    0.050505    0.010101    0.060606   \n",
      "292     melville      3.93    0.020202    0.020202    0.020202    0.070707   \n",
      "293     melville      3.68    0.050505    0.040404    0.010101    0.040404   \n",
      "294     melville      3.78    0.070707    0.040404    0.040404    0.010101   \n",
      "295     melville      4.20    0.050505    0.020202    0.030303    0.030303   \n",
      "296     melville      3.96    0.010101    0.030303    0.000000    0.000000   \n",
      "297     melville      3.60    0.050505    0.030303    0.030303    0.020202   \n",
      "298     melville      3.79    0.020202    0.030303    0.010101    0.010101   \n",
      "299     melville      3.81    0.030303    0.040404    0.040404    0.050505   \n",
      "300  shakespeare      3.66    0.010101    0.020202    0.000000    0.000000   \n",
      "301  shakespeare      3.28    0.010101    0.000000    0.000000    0.010101   \n",
      "302  shakespeare      3.57    0.010101    0.010101    0.030303    0.030303   \n",
      "303  shakespeare      3.51    0.000000    0.030303    0.030303    0.010101   \n",
      "304  shakespeare      3.47    0.000000    0.030303    0.020202    0.010101   \n",
      "305  shakespeare      3.57    0.020202    0.010101    0.030303    0.020202   \n",
      "306  shakespeare      3.37    0.010101    0.050505    0.030303    0.040404   \n",
      "307  shakespeare      3.80    0.020202    0.020202    0.030303    0.050505   \n",
      "308  shakespeare      3.13    0.040404    0.030303    0.020202    0.000000   \n",
      "309  shakespeare      3.55    0.020202    0.040404    0.030303    0.010101   \n",
      "\n",
      "     FEATURE2_4  FEATURE3  SENTENCELENGTH  PREP_0  PREP_1  PREP_2  PREP_3  \\\n",
      "290    0.020202  0.083333       25.000000    0.03    0.00    0.01    0.01   \n",
      "291    0.020202  0.166667       20.000000    0.02    0.04    0.00    0.00   \n",
      "292    0.020202  0.250000       20.000000    0.02    0.02    0.00    0.00   \n",
      "293    0.060606  0.133333       20.000000    0.01    0.03    0.01    0.02   \n",
      "294    0.010101  0.428571       33.333333    0.02    0.01    0.00    0.01   \n",
      "295    0.020202  0.000000       20.000000    0.04    0.01    0.00    0.00   \n",
      "296    0.000000  0.285714       25.000000    0.01    0.01    0.02    0.00   \n",
      "297    0.010101  0.125000       20.000000    0.00    0.02    0.01    0.00   \n",
      "298    0.010101  0.071429       20.200000    0.01    0.01    0.01    0.00   \n",
      "299    0.030303  0.000000       20.000000    0.04    0.02    0.03    0.00   \n",
      "300    0.020202  0.000000        6.666667    0.01    0.00    0.00    0.00   \n",
      "301    0.000000  0.000000        6.250000    0.01    0.00    0.00    0.00   \n",
      "302    0.030303  0.000000        9.090909    0.04    0.00    0.00    0.00   \n",
      "303    0.040404  0.000000       20.000000    0.02    0.00    0.02    0.00   \n",
      "304    0.020202  0.055556        9.090909    0.02    0.00    0.01    0.01   \n",
      "305    0.010101  0.047619       10.000000    0.02    0.00    0.02    0.01   \n",
      "306    0.030303  0.000000       12.500000    0.00    0.01    0.00    0.00   \n",
      "307    0.020202  0.000000       33.333333    0.05    0.01    0.01    0.00   \n",
      "308    0.010101  0.000000       25.000000    0.01    0.00    0.02    0.01   \n",
      "309    0.010101  0.000000      100.000000    0.03    0.00    0.00    0.01   \n",
      "\n",
      "     PREP_4  FUNCTIONWORD_0  FUNCTIONWORD_1  FUNCTIONWORD_2  FUNCTIONWORD_3  \\\n",
      "290    0.01            0.00            0.00            0.00            0.00   \n",
      "291    0.01            0.00            0.00            0.00            0.00   \n",
      "292    0.00            0.00            0.00            0.00            0.00   \n",
      "293    0.00            0.01            0.00            0.00            0.00   \n",
      "294    0.00            0.01            0.01            0.01            0.00   \n",
      "295    0.00            0.00            0.01            0.00            0.01   \n",
      "296    0.00            0.00            0.00            0.00            0.00   \n",
      "297    0.00            0.00            0.00            0.00            0.00   \n",
      "298    0.02            0.00            0.00            0.00            0.00   \n",
      "299    0.01            0.00            0.00            0.00            0.01   \n",
      "300    0.00            0.00            0.00            0.00            0.00   \n",
      "301    0.00            0.00            0.00            0.00            0.00   \n",
      "302    0.00            0.00            0.00            0.00            0.00   \n",
      "303    0.00            0.00            0.00            0.00            0.00   \n",
      "304    0.00            0.01            0.03            0.00            0.00   \n",
      "305    0.00            0.00            0.00            0.00            0.00   \n",
      "306    0.00            0.00            0.01            0.00            0.00   \n",
      "307    0.00            0.00            0.00            0.00            0.00   \n",
      "308    0.01            0.00            0.00            0.00            0.00   \n",
      "309    0.01            0.00            0.00            0.00            0.00   \n",
      "\n",
      "     FUNCTIONWORD_4  \n",
      "290             0.0  \n",
      "291             0.0  \n",
      "292             0.0  \n",
      "293             0.0  \n",
      "294             0.0  \n",
      "295             0.0  \n",
      "296             0.0  \n",
      "297             0.0  \n",
      "298             0.0  \n",
      "299             0.0  \n",
      "300             0.0  \n",
      "301             0.0  \n",
      "302             0.0  \n",
      "303             0.0  \n",
      "304             0.0  \n",
      "305             0.0  \n",
      "306             0.0  \n",
      "307             0.0  \n",
      "308             0.0  \n",
      "309             0.0  \n"
     ]
    }
   ],
   "source": [
    "# We can inspect what the features look like\n",
    "print(df[290:310])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    melville       0.86      0.83      0.85        60\n",
      " shakespeare       0.84      0.87      0.85        60\n",
      "\n",
      "    accuracy                           0.85       120\n",
      "   macro avg       0.85      0.85      0.85       120\n",
      "weighted avg       0.85      0.85      0.85       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now we train a classifier similar to what we did for Named Entity classifcation\n",
    "x = df.iloc[:, 1:len(df.columns)]\n",
    "y = df.iloc[:, [0]]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "c_tree = DecisionTreeClassifier(max_depth=4)\n",
    "c_tree.fit(x_train, y_train)\n",
    "\n",
    "# ... and evaluate it\n",
    "predicted = list(c_tree.predict(x_test))\n",
    "gold = list(y_test.loc[:, \"GOLD\"])\n",
    "print(classification_report(gold,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared with the original one with three given features, the percentage of precision, recall, f1-score is higher after more features are added, which means accuracy of the classifier is higher."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
